{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94f8d4-cb74-4780-9f7f-ff6ea6921dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from config import Config\n",
    "from audiomodel import AudioProcessing\n",
    "from audiotools import AudioSignal\n",
    "\n",
    "def make_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def build_model(cfg):\n",
    "    from audiocraft.models.loaders import load_compression_model, load_lm_model\n",
    "    \"\"\"Instantiate models and optimizer.\"\"\"     \n",
    "    compression_model = load_compression_model('facebook/audiogen-medium', device=cfg.device)\n",
    "    lm = load_lm_model('facebook/audiogen-medium', device=cfg.device)\n",
    "    return compression_model, lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def558a9-cffb-4063-95da-807c9f526505",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=Config()\n",
    "print(cfg.sample_rate)\n",
    "compression_model, lm = build_model(cfg)\n",
    "compression_model.eval()\n",
    "model = AudioProcessing(cfg, lm)\n",
    "model.load_state_dict(torch.load(\"./weight/best.pth\"), strict=False)\n",
    "model.eval()\n",
    "print(\"load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6966976-735a-4278-9ba9-4325357b6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiotools import AudioSignal\n",
    "from IPython.display import Audio\n",
    "\n",
    "for _ in range(2):\n",
    "    tok, gen_audio = model.inference([\"(gun)0.6 is (reloaded)1.5\"], compression_model, duration=3.0)\n",
    "    display(Audio(gen_audio[0][0].cpu().detach(), rate=cfg.sample_rate))\n",
    "    \n",
    "for _ in range(2):\n",
    "    tok, gen_audio = model.inference([\"gun is reloaded\"], compression_model, duration=3.0)\n",
    "    display(Audio(gen_audio[0][0].cpu().detach(), rate=cfg.sample_rate))\n",
    "\n",
    "# [4, 5, 1536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb78f50-d73f-491c-8450-e0bc17c0f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiotools import AudioSignal\n",
    "from IPython.display import Audio\n",
    "\n",
    "for _ in range(10):\n",
    "    print(\"작은 가중치\")\n",
    "    tok, gen_audio = model.inference([\"metal impact with (reverb, echo)0.3\"], compression_model, duration=3.0)\n",
    "    # display(Audio(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate))\n",
    "    AudioSignal(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate).widget()\n",
    "\n",
    "for _ in range(10):\n",
    "    print(\"그냥 가중치\")\n",
    "    tok, gen_audio = model.inference([\"metal impact with (reverb, echo)1.5\"], compression_model, duration=3.0)\n",
    "    # display(Audio(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate))\n",
    "    AudioSignal(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate).widget()\n",
    "\n",
    "for _ in range(10):\n",
    "    print(\"없는\")\n",
    "    tok, gen_audio = model.inference([\"metal impact\"], compression_model, duration=3.0)\n",
    "    # display(Audio(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate))\n",
    "    AudioSignal(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate).widget()\n",
    "\n",
    "for _ in range(5):\n",
    "    tok, gen_audio = model.inference([\"metal impact with reverb, echo\"], compression_model, duration=3.0)\n",
    "    # display(Audio(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate))\n",
    "    AudioSignal(gen_audio[0][0].cpu().detach(), sample_rate=cfg.sample_rate).widget()\n",
    "\n",
    "# [4, 5, 1536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4430bb0-a3d3-41d5-b5d5-2cc54b5f8058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2374ace4-db53-450e-8b32-1a07e6c0ae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    tok, gen_audio = model.inference([\"The sound of dog and cat\"], compression_model, duration=6.0)\n",
    "    display(Audio(gen_audio[0][0].cpu().detach(), rate=cfg.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c02c9-c395-452c-97e3-72658af0cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    tok, gen_audio = model.inference([\"The sound of reloading a gun\"], compression_model, duration=3.0)\n",
    "    display(Audio(gen_audio[0][0].cpu().detach(), rate=cfg.sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2706c177-0ed6-44a1-9319-6b4414749059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
